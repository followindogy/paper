\chapter{相关技术的研究使用}
本章主要介绍了一些已有的CPU/GPU异构计算优化方法和编译原理中一些调整代码序列的方法，
通过对已有的优化方法进行总结比较，提出本文一种基于代码移动来迁移、合并核函数的数据交换
操作的优化方法。

\section{GPU编程优化方法}
GPU的物理结构更加适合大数据、高并发的复杂计算，任何优化GPU编程的方法都是基于GPU物理
特性充分发挥GPU计算性能来实现的。本节将介绍、对比一些业界主流的GPU编程优化方法以及
每种方法的使用场景。

\subsection{向量化}
\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{figure3.eps}
\caption{向量化}\label{figure3}
\end{figure}
程序员可以在编写代码之前手动分析GPU应用程序中数据特点，再根据GPU结构特性去确定如何组织、存储、访问
数据以及确定程序逻辑可以达到优化程序的目的。向量计算是图像算法中经常使用的计算方法，我们可以使用
数组很好地表示一维向量进行计算。但是在向量乘法、加法等计算操作中，向量中每一个维度的操作基本都是相同
而且相互不干扰的，具有很高的并行性。核函数中使用数组表示一维向量时，在向量计算中仅仅使用了
单个线程循环迭代处理向量中每个维度的计算，没有利用到向量的计算并行性和GPU的多核特点，效率较低。
主流GPU编程语言CUDA和OpenCL都提供了数据向量化方法，用专有的数据结构去表示向量。如图~\ref{figure3}所示，向量化后的计算，
每一个维度的的操作都会分配到不同核心上的
线程执行，不再是整个向量维度的计算都在一个线程上。
向量化的数据结构在GPU中计算时可以充分利用GPU多核特性
，每一个维度的计算都放在了不同核心上的线程，可以加速向量计算。

\subsection{优化GPU内存使用}
第一章简单描述了GPU内存结构，较为复杂，由常量内存、
纹理内存、共享内存和全局DRAM等组成。不同种类的存储器特点和适用场景差别很大，表~\ref{table1}
简单列出了不同GPU储存器的一些特点，GPU程序员必须要清楚地了解
GPU的内存特点再根据使用场景具体选择。
编写代码时，如何设计数据在GPU内存中的存储方式也是一种很重要的优化GPU程序的方法。
寄存器是GPU计算单元访问延迟最低的存储器，GPU程序运行时会自动将一些中间数据存储到
寄存器上加速下次读取。但是GPU会将一些线程私有变量存到线程的寄存器上，程序员定义了过多的线程私有变量
会导致程序运行时一些GPU线程内寄存器不足，换而使用显卡中的局部内存，增加了访问延迟。
我们可以把GPU运行时不发生变化的数据存储到GPU常量内存中，单个线程对
常量内存中数据的访问会使GPU将该数据广播到同一线程束中的其他线程，由此可以减少整个程序对常量内存
的读取次数。
\begin{table}[b]
  \centering
  \caption{GPU内存特性}
  \begin{tabular}{llll}
    \hline
    存储器     & 位置      & 访问权限 & 变量生存周期    \\
    \hline
    寄存器     & GPU片上   & GPU可读/写  & 与线程相同    \\
    局部存储器 & 板载显卡  & GPU可读/写  & 与线程相同    \\
    共享内存   & GPU片上   & GPU可读/写  & 与线程块相同   \\
    常量内存   & 板载显卡  & CPU/GPU可读/写  &  与程序相同     \\
    纹理内存   & 板载显卡  & CPU/GPU可读/写  &  与程序相同         \\
    全局内存   & 板载显卡  & CPU/GPU可读/写  &  与程序相同  \\

    \hline
  \end{tabular}
  \label{table1}
\end{table}
共享内存是GPU片上线程块内所有线程可以读写的共享存储空间，是线程块内线程数据交互延迟最低的通信方式。
当程序中一些数据是线程块内所有线程共享的，我们可以使用共享内存代替全局内存，降低线程之间相互通信的延迟。
纹理内存也是GPU中只读内存，被设计用来存储空间局部性比较高的数据。由于GPU结构中没有
cache来缓存时间局部性的数据，如何利用好数据的空间局部性就是一个很重要的优化方法。特别是在图形计算中
，每个像素点的在空间上的联系非常紧密，空间复杂度很高，使用纹理内存的读取特性可以很容易读取空间上联系
紧密的数据，加速内存访问速度。
%CUDA和OpenCL都提供了纹理内存的使用接口，程序员可以根据具体应用数据访问的空间局部性决定是否使用纹理内存。
综合本小节的描述可以看出，GPU中不同内存的性质差别很大，根据具体场景选择
合适的存储器将会很大程度上优化GPU程序。

\subsection{嵌套循环展开}
\begin{lstlisting}[label=Listing1,caption=嵌套循环,language=C++, keywordstyle=\color{blue!70},commentstyle=\color{red!50!green!50!blue!50},frame=shadowbox, rulesepcolor=\color{red!20!green!20!blue!20}] 
void addmatrix(vector<vector<int>>& matrix)
	{
	    int m = matrix.size();
        int n = matrix[0].size();
        for(int i=0; i<m; i++)
            for(int j=0; j<n; j++)
                matrix[i][j] += 1;
        return;
    }		
\end{lstlisting}

\begin{lstlisting}[label=Listing2,caption=嵌套循环展开,language=C++, keywordstyle=\color{blue!70},commentstyle=\color{red!50!green!50!blue!50},frame=shadowbox, rulesepcolor=\color{red!20!green!20!blue!20}] 
void addmatrix(vector<vector<int>>& matrix)
	{
	    int m = matrix.size();
        int n = matrix[0].size();
        for(int i=0; i<m*n; i++)
            {
			    int j = i/n;
			    int k = i%n;
                matrix[j][k] += 1;
			}
        return;
    }		
\end{lstlisting}
GPU之所以能够快速处理大数据并行计算是因为其拥有很多个计算核心，可以同时运行多个线程。GPU程序中的核函数都是
一些计算量很大的循环结构，循环结构中每一次迭代都是独立的，这样GPU就可以启动很多个线程去运行循环结构中的每一次
迭代计算。由此可见，循环结构的迭代次数越多，加速效果越明显。但是GPU程序中循环不都是简单的单层循环，更常见的是
逻辑比较复杂的多层嵌套循环。
在核函数里的多层嵌套循环结构中，只有最里层的循环结构是同时在不同线程上计算的。这样的计算方式使得
嵌套循环结构没有完全利用GPU的多核优势，闲置了很多计算资源。
嵌套循环展开是指预处理GPU程序时把一些核函数中的二层或者多层嵌套循环展开、合并成单个循环。
如代码块~\ref{Listing1}、~\ref{Listing2}所示两段代码都是实现了一个矩阵所有元素加1的简单操作。显然两段代码的时间复杂
都是相同的,嵌套展开后的代码段还增加了计算举证行、列索引的操作。如果在普通CPU上执行的话，显然代码块~\ref{Listing1}
中的代码段执行的会更快，因为CPU是没有足够的计算单元来开启多个线程并行计算该循环的。但是GPU的多核特性正是针对
处理并行程度高的计算的，代码块~\ref{Listing2}把代码块~\ref{Listing1}中的嵌套循环合并成一个迭代比较大的单个循环，这样允许
GPU开启更多的线程去计算该核函数，得到更好的优化效果。这里只拿矩阵自加作为例子介绍嵌套循环展开，当计算比较复杂，
每一次迭代的计算量都比较大时，嵌套循环展开对GPU核函数的优化将是十分明显的。


\subsection{线程配置}
本小节以CUDA平台为例简单描述GPU编程中的线程配置。CUDA的线程设计以网格(Grid)、线程块(Block)和线程(Thread)组成，
具体结构如图~\ref{figure6}所示。GPU上所有的计算单元被划分为两到三个网格，每个网格包含一定数量的线程块，目前
最多为65535个线程块，每个线程块再由一定数量的线程组成，目前主流显卡线程块最多可以包含1024个线程。如何配置好
如此多的线程对GPU程序员将是一个很大的挑战，也是优化GPU程序一个很重要的维度。同一线程块内的线程具有相同的指
令地址，不但能够并发执行，而且可以通过GPU片上共享内存和栅栏实现块内快速通信。这样，程序员在设计CUDA程序时需要
优先把相互通信量较大、较为频繁或者需要同步的线程分配到同一线程块内，利用共享内存降低线程通信延迟，同时把不需
要通信的线程分配到不同线程块内，使其并行粒度更高。CUDA架构通过块间粗粒度并行，块内细粒度并行两种方式来组织线程。
多个计算单元加上一些寄存器和共享存储器组成一个多元处理器。每个线程块最终都是交给一个多元处理器执行的。
\begin{figure}
\centering
\includegraphics[width=0.6\linewidth]{figure6.eps}
\caption{GPU线程结构}\label{figure6}
\end{figure}
程序运行时，GPU任务分配单元将网格分配到GPU芯片上。CUDA平台启动时，需要将网格配置信息从CPU下发到GPU，
任务分配单元依据配置信息将线程块块分配到多元处理器上。任务分配单元采用轮询策略：轮询遍历多元处理器有没有足够的资源
来执行新的线程块，如果有则给多元处理器分配一个新的线程块。决定是否成功分配的条件有：块运行时需要的寄存器数量，
共享存储器数量，以及其它的一些限制条件。任务分配单元在任务分配中保持公平，然而我们可以通过手动编程设置块内线程数量，
线程使用的寄存器数和共享存储器数来间接控制，保证处理单元负载均衡。任务以这种方法分配使程序具备了很大的可扩展性：
由于每个子任务都能在任意一个多元处理单元上执行，CUDA程序在核心数量不同的处理器上都能正常运行，隐藏了硬件差异。
程序员需要根据具体应用场景将任务拆分为互不相干、可以并行计算的粗粒度子任务，再将每个子任务拆分为能够尽可能利用
线程块内计算资源、存储资源的细粒度指令集。
现有的显卡同一时刻只能执行一个核函数，但是在Fermi架构中可以在同一时刻运行多个核函数。
例如程序员可以在一个内核访问GPU数据的同时，开启另一个内核进行计算，可以很大程度上提高程序运行效率。
线程是串行执行指令的，这就要求每个线程不可以有过多的循环逻辑或者需要过多的存储资源。
当然我们也不应该在单个线程块内分配过多的线程，可能由于参数和中间变量过多导致存储资源不足，降低多元处理器计算速度。
在问题相对复杂时，程序员也可以手动测试一些配置参数的运行速度，选择一个最合适的线程配置参数。

\section{一般代码优化}
程序员编写的代码不总是十全十美，编译器可以自动在不改变程序运行效果的前提下帮助我们进行一些代码优化，使之运行时
的空间效率和时间效率得到提高。编译原理中的代码优化是指通过重排、删除、合并或改变程序片段等策略，使程序代码发生
形式上的改变。本节讨论的是编译阶段的一些代码优化方法，不考虑程序本身算法的效率。
\subsection{变量优化}
任何一个程序离不开变量的定义和变量计算，一些基于变量的简单优化方法可以起到一定的优化效果。表~\ref{table2}给出了
常量合并的传播的优化方法，在编译时就已经可以计算出的常量不需要放到程序执行时计算，减少程序运行时间。
\begin{table}[h]
  \centering
  \caption{常量合并与传播优化}
  \begin{tabular}{p{7cm}<{\centering}p{7cm}<{\centering}}
    \hline
    优化前代码     & 优化后代码   \\
    \hline
    X = 3;         & X = 3;    \\
    Y = X + 2;       & Y = 5; \\
    Z = 3 * Y;      & Z = 15; \\
   \hline
  \end{tabular}
  \label{table2}
\end{table}
表~\ref{table3}描述了公共子表达式外提的优化实例，把两个表达式中重复出现的部分外提出来单独运算，显然优化前
进行了4次加法，优化后进行了3次加法，可以起到一定的加速作用。
\begin{table}[h]
  \centering
  \caption{公共字表达式外提优化}
  \begin{tabular}{p{7cm}<{\centering}p{7cm}<{\centering}}
    \hline
    优化前代码      & 优化后代码   \\
    \hline
    x = b+c+d;      & t = b+c;    \\
    y = b+c+e;      & x = t+d; \\
                    & y = t+e; \\
   \hline
  \end{tabular}
  \label{table3}
\end{table}
还有一些变量优化的场景，比如编译原理中描述的死代码删除。死代码删除是指某个变量的两次定值之间程序没有对该变量的引用，这说明
变量的第一次赋值是多余的，可以删除。一些无用转移语句可以导致一些分支在编译的时候就确定了是否执行，这样编译器可以在编译的时候
就丢弃这些转移逻辑，提升代码执行速度。
\subsection{循环优化}
循环逻辑是程序中重复执行的代码块，对循环结构的优化将会带来更加显著的优化效果。将循环中的不变量或者不变代码外提是最简单的循环优化
方法。表~\ref{table4}中将循环中的不变量2*x+1提出循环外之后，避免了每次迭代时对2*x+1表达式的计算，优化后只需在循环开始之前计算一次，
大大减少了程序运行时间。
\begin{table}[h]
  \centering
  \caption{循环不变量外提}
  \begin{tabular}{p{7cm}<{\centering}p{7cm}<{\centering}}
    \hline
    优化前代码             & 优化后代码   \\
    \hline
    x = c;                    & x = c;    \\
    for(i=0; i<100; i++)      & t = 2*x+1; \\
      array[i] = 2*x+1;       & for(i=0; i<100; i++) \\
	                          &    array[i] = t;  \\
   \hline
  \end{tabular}
  \label{table4}
\end{table}
将循环体内的运算强度削弱也是一种循环优化的方法，在表~\ref{table5}中，我们在循环体内使用加法代替乘法并且得到相同的计算结果。
这种逻辑上的更改不但没有破坏程序结果，而且将每次迭代中的乘法换成了计算强度相对较小的加法，这种优化的效果将随着循环体执行
次数的增加而增加。
\begin{table}[h]
  \centering
  \caption{循环内运算强度削弱}
  \begin{tabular}{p{7cm}<{\centering}p{7cm}<{\centering}}
    \hline
    优化前代码             & 优化后代码   \\
    \hline
    for(i=0; i<100; i++)      & t = 0; \\
       t = i*5;                & for(i=0; i<100; i++)\\ 
                             &    t += 5;\\
  \hline
  \end{tabular}
  \label{table5}
\end{table}
至于如何确定程序中的循环结构和循环中不变量将在后续章节控制流分析和数据流分析中描述。

\section{控制流分析和循环查找}
循环是程序中常见的一种逻辑结构，想要针对循环进行优化必须先确定程序中的循环结构。常见编程语言都有一些用于构造循环的语法，如FORTRAN
语言中的DO语句，C/C++等语言中的for，REPEAT，Do-while等语句，代码中有循环语句构造的循环结构是比较容易找出的。但是一些条件转移语句
和无条件转移语句等形成的循环结构复杂，需要分析程序的控制流才能确定。
\subsection{基本块和控制流图}
编译原理中的基本块是指程序中的一组顺序执行的代码序列，基本块的第一行为唯一入口，最后一行为唯一出口。基本块的特点是只能从入口进入，
出口退出，基本块内语句按照顺序无转移地执行。我们可以按照如下方法来确定代码中的基本块，首先找到每个基本块的入口语句，程序的第一行
语句，由条件转移或者无条件转移到的语句，以及紧跟在转移语句之后的语句都是基本块入口。然后根据所有基本块的入口构造基本块，由入口语句
到下一个入口语句(不包含该语句)之间的所有代码构成一个基本块，或者由入口语句到一个最近的转移语句(包含该语句)之间的语句构成一个基本块。
最后所有没有被包含到基本块中的语句，将是程序中的任何控制语句不能到达的，即一定不会被执行，直接删除。
\begin{lstlisting}[label=Listing3,caption=基本块划分,language=C, keywordstyle=\color{blue!70},commentstyle=\color{red!50!green!50!blue!50},frame=shadowbox, rulesepcolor=\color{red!20!green!20!blue!20}] 
read(input)
i = i+1
if(i>input) goto(11) 
read(j)
if(i==1) goto(8)
sum = sum*2+j
goto(9)
sum = sum+j
i=i+1
goto(3)
write(sum)
\end{lstlisting}
代码块~\ref{Listing3}伪代码中，根据上述基本块确定规则可知，(1)是整个程序入口,(3)(8)(9)(11)是转移语句转移到的语句，
(4)(6)(8)(11)是转移语句之后的语句，所以(1)(3)(4)(6)(8)(9) (11)为入口语句。再根据基本块构造规则可以得到7个基本块，
分别是语句(1)和(2);语句(3);语句(4)和(5);语句(6)和(7);语句(8);语句(9)和(10);语句(11)。
程序被划分成一些基本块之后，可以依据程序中基本块的执行顺序用有向边把基本块链接起来，这就是程序的控制流图。
\begin{figure}
\centering
\includegraphics[width=0.6\linewidth]{figure7.eps}
\caption{控制流图}\label{figure7}
\end{figure}
图~\ref{figure7}中描述的正是代码块~\ref{Listing3}中伪代码的控制流图，是一个唯一首节点的有向图。

\subsection{控制流分析}
在上一章节得到的程序控制流图中，存在具有如下性质的节点序列，则构成一个循环。首先节点序列是强连通的，序列中任意两个节点之间都一定存在
一条通路，而且通路上的所有节点都属于该节点序列。特别是节点序列中只包含一个节点，则该节点必须要有一条有向边指向自身。而且节点序列只能有
一个入口节点，入口节点一定是从序列外有某个节点指向它或者入口节点就是程序控制流图的首节点。因此，控制流图中的循环一定是强联通性和入口
唯一性的节点序列。
\begin{figure}
\centering
\includegraphics[width=0.6\linewidth]{figure8.eps}
\caption{控制流图和循环查找}\label{figure8}
\end{figure}
图~\ref{figure8}是一个比较复杂程序的控制流图，显然\{5\},\{4,5,6,7\},\{2,3,4,5,6,7\}满足循环结构的强联通性和入口节点唯一性，是程序中的循环结构。
节点{2,4}虽然也有强联通性，但是节点(2)和(4)都可以作为这个序列的入口，不具有入口唯一性，因此不是一个循环。
编译原理理论提供了如何根据控制流图找出程序中循环结构的方法。首先定义了节点的必经节点，即程序进入该节点之前必须要经过的节点，节点(1)是
所有节点的必经节点。一个节点的所有必经节点构成必经节点集。图~\ref{figure8}中，每个节点的必经节点集为：D(1)=\{1\},D(2)=\{1,2\},D(3)=\{1,2,3\}
,D(4)=\{1,2,4\},D(5)=\{1,2,4,5\},D(6)=\{1,2,4,6\},D(7)=\{1,2,4,7\}。节点n的必经节点集为D，如果在D中存在一点m而且在程序控制流图中存在有向边<n, m>
,则称有向边<n, m>是一条回边。以节点(7)为例，节点(4)是它的必经节点而且存在有向边<7,4>,所以<7,4>为一条回边。则有节点(4)、节点(7)以及所有通路到达
(7)而且该通路不经过(4)的所有节点结合构成一个循环，且节点(4)为该循环唯一入口。
程序中回边的数量和循环数量一致。

\section{数据流分析}
数据流分析主要是收集、分析整个程序内的数据及控制流相关的基本信息，是实现循环优化和全局优化的必要准备工作。通过变量的引用-定值链和定值-引用链分析，
确定一些变量在程序语句中可迁移的范围，这也是本文优化GPU程序算法的一个重要支撑。
\subsection{程序中的点和通路}
我们认为控制流图基本块中前后相继的两个语句之间是有一个点的，同样两个相继基本块之间也是有一个点的。从全局代码出发，所有点的序列为
$P_1$,$P_2$,$\cdot\cdot\cdot$,$P_n$。
则对任意的节点$P_i$一定满足如下两个条件:第一，若$P_i$是语句$d_i$之前最近的一个点，则$P_{i+1}$是紧跟在同一基本块中语句$d_i$之后的点；第二，$P_i$若是某个
基本块中最后一个点，则$P_{i+1}$是该基本块后记基本块的第一个节点。通路是指一个点可以通过控制流图中的有向边走到另一个点，显然所有点都有
到程序中最后一个点的通路。
\subsection{到达-定值数据流方程}
变量X在某点d的定值到达另一点u，是指在程序控制流图中存在一条从d到u的通路，而且在该条通路上没有对变量X再定值，则称点d为变量X在点u的定值点。
所有程序中的变量都以两种方式出现，
一是出现在等号的左边，即定义变量或者改变变量的值，称为定值；
二是变量出现在等号的右边作为表达式的一部分或者作为函数的形参，变量本身不会改变，称为变量的引用。
值得注意的是定值不仅仅是赋值一种，函数的引用参数和指针都是一种定值的方式。

\subsection{引用-定值链}
程序中某点P引用了变量X的值，我们把能到达P的变量X的所有定值点成为变量X在引用点P的引用-定值链(ud链)。在循环优化中，利用变量的引用-定值链可以找出
循环中不变的计算。在控制流基本块中，变量X的引用点P之前有X的定值点d，而且X在d点的定值可以到达P，则X在点P的ud链为\{d\}。如果基本块中，变量X的引用
点之前没有X的定值点，则在进入基本块时X的所有定值点都能到达点P。在优化循环时，循环中的语句一旦满足该语句引用的所有变量的ud链都在循环之外的条件，就
可以认为该行语句执行的计算在循环每一次迭代时都是不变的，即可以移出循环之外执行。

\subsection{定值-引用链}
定值-引用链(du链)是和ud链相对应的，du链是指程序在某点P对变量X的定值可以到达的所有变量X的引用的集合。基本块B内，若在P点之后有对变量X的重新定值，
则点P到距离P最近的X的定值点之间的所有X的引用点集合是变量X在点P的du链。若基本块B内不存在对变量X的再定值，则B内所有对X的引用点和B之后基本块中对
X在P点处的定值的引用点全体构成这条du链。根据X的du链，我们可以求出在离开基本块B时，哪些变量X的定值能够到达后续基本块中X的引用点。那么根据这些条件
可以确定哪些变量的定值在某一区间内不被引用，则在此区间内的定值为无效定值。









